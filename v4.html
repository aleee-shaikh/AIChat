<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Mobile Voice Gemini Agent</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body {
      font-family: sans-serif;
      margin: 0;
      background: black;
      color: white;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    canvas#avatar {
      width: 100%;
      max-height: 50vh;
      background: black;
    }
    #chatbox {
      width: 90%;
      max-height: 25vh;
      overflow-y: auto;
      background: #f0f0f0;
      color: black;
      padding: 10px;
      margin-top: 10px;
      border-radius: 10px;
    }
    .msg { padding: 6px; border-radius: 4px; margin-bottom: 6px; }
    .user { background: #d0ebff; text-align: right; }
    .bot  { background: #fff3cd; text-align: left; }
    #inputArea {
      margin-top: 10px;
      display: flex;
      width: 90%;
    }
    #input {
      flex: 1;
      padding: 8px;
      border-radius: 5px;
      border: 1px solid #ccc;
    }
    #send {
      padding: 8px 12px;
      margin-left: 8px;
      border: none;
      border-radius: 5px;
      background: #007bff;
      color: white;
    }
    #btnMic {
      position: fixed;
      bottom: 10px;
      left: 10px;
      background: #10b981;
      color: white;
      padding: 10px 15px;
      border: none;
      border-radius: 6px;
      font-size: 16px;
      z-index: 999;
    }
  </style>
</head>
<body>

<canvas id="avatar" width="600" height="300"></canvas>
<div id="chatbox"></div>
<div id="inputArea">
  <input id="input" placeholder="Ask me anythingâ€¦" />
  <button id="send">Send</button>
</div>
<button id="btnMic">ðŸŽ¤ Speak</button>

<!-- jQuery -->
<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>

<script>
const API_KEY = "YOUR_GEMINI_API_KEY_HERE";
const MODEL = "models/gemini-2.5-flash";
const ENDPOINT = `https://generativelanguage.googleapis.com/v1/${MODEL}:generateContent?key=${API_KEY}`;

function addMessage(text, cls) {
  const msg = $('<div class="msg"></div>').addClass(cls).text(text);
  $('#chatbox').append(msg);
  $('#chatbox').scrollTop($('#chatbox')[0].scrollHeight);
}

function speak(text) {
  const utterance = new SpeechSynthesisUtterance(text);
  utterance.lang = "en-US";
  speechSynthesis.speak(utterance);
}

function sendToGemini(prompt) {
  addMessage("ðŸ¤” Thinking...", "bot");
  $.ajax({
    method: "POST",
    url: ENDPOINT,
    contentType: "application/json",
    data: JSON.stringify({ contents: [{ parts: [{ text: prompt }] }] }),
    success: (resp) => {
      const reply = resp?.candidates?.[0]?.content?.parts?.[0]?.text || "No response";
      $('.bot').last().text(reply);
      speak(reply);
    },
    error: () => {
      $('.bot').last().text("âŒ Error");
      speak("There was an error.");
    }
  });
}

$('#send').click(() => {
  const txt = $('#input').val().trim();
  if (!txt) return;
  addMessage(txt, "user");
  $('#input').val('');
  sendToGemini(txt);
});
$('#input').keypress((e) => {
  if (e.which === 13) $('#send').click();
});
</script>

<!-- Voice Input Script -->
<script>
let recognition;
let isRecognitionAvailable = false;
let mediaRecorder, audioChunks = [];

function sendToWhisper(blob) {
  console.log("ðŸŽ§ Whisper fallback: blob ready", blob);
  // You can upload blob to your server or Whisper API here
}

function startMicRecording() {
  navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
    mediaRecorder = new MediaRecorder(stream);
    audioChunks = [];
    mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
    mediaRecorder.onstop = () => {
      const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
      sendToWhisper(audioBlob);
    };
    mediaRecorder.start();
    setTimeout(() => mediaRecorder.stop(), 5000);
  }).catch(err => {
    alert("Mic access error");
    console.error(err);
  });
}

function setupSpeechRecognition() {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SpeechRecognition) return false;
  recognition = new SpeechRecognition();
  recognition.lang = 'en-US';
  recognition.interimResults = false;
  recognition.continuous = false;
  recognition.onresult = (event) => {
    const text = event.results[0][0].transcript.trim();
    addMessage(text, "user");
    sendToGemini(text);
  };
  recognition.onerror = (e) => {
    console.error("SpeechRecognition error:", e.error);
  };
  return true;
}

document.getElementById("btnMic").addEventListener("click", () => {
  if (setupSpeechRecognition()) {
    recognition.start();
    console.log("ðŸŽ¤ SpeechRecognition started");
  } else {
    console.log("ðŸŽ¤ Fallback to MediaRecorder");
    startMicRecording();
  }
});
</script>

<!-- Avatar Drawing -->
<script>
const canvas = document.getElementById("avatar");
const ctx = canvas.getContext("2d");

function drawFace() {
  const w = canvas.width;
  const h = canvas.height;
  ctx.clearRect(0, 0, w, h);

  // Face
  ctx.fillStyle = "black";
  ctx.fillRect(0, 0, w, h);

  // Eyes
  ctx.fillStyle = "white";
  ctx.beginPath();
  ctx.ellipse(w / 3, h / 3, 40, 60, 0, 0, Math.PI * 2);
  ctx.ellipse(2 * w / 3, h / 3, 40, 60, 0, 0, Math.PI * 2);
  ctx.fill();

  // Pupils
  ctx.fillStyle = "black";
  ctx.beginPath();
  ctx.arc(w / 3, h / 3, 12, 0, Math.PI * 2);
  ctx.arc(2 * w / 3, h / 3, 12, 0, Math.PI * 2);
  ctx.fill();

  // Mouth
  ctx.fillStyle = "red";
  ctx.beginPath();
  ctx.arc(w / 2, 2 * h / 3, 40, 0, Math.PI, false);
  ctx.fill();
}

drawFace();
</script>

</body>
</html>
